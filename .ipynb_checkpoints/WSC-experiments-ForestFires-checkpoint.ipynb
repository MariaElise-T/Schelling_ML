{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ceeffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from tslearn.clustering import TimeSeriesKMeans\n",
    "from tslearn.datasets import CachedDatasets\n",
    "from tslearn.preprocessing import TimeSeriesScalerMeanVariance, \\\n",
    "    TimeSeriesResampler\n",
    "from tslearn.clustering import silhouette_score\n",
    "import seaborn as sns\n",
    "from tslearn.utils import to_time_series_dataset\n",
    "from tslearn.clustering import silhouette_score\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from yellowbrick.cluster import SilhouetteVisualizer\n",
    "from yellowbrick.cluster import KElbowVisualizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812b6821",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import simulation data - Forest Fires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb471bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = list()\n",
    "fine = list()\n",
    "burning = list()\n",
    "burnedout = list()\n",
    "    \n",
    "for j in range(100):\n",
    "    \n",
    "    input_file_name = \"train_inputs_\" + str(j) + \".csv\"    \n",
    "    fine_file_name = \"train_outputs_fine_\" + str(j) + \".csv\"\n",
    "    burning_file_name = \"train_outputs_burning_\" + str(j) + \".csv\"\n",
    "    burnedout_file_name = \"train_outputs_burnedout_\" + str(j) + \".csv\"\n",
    "\n",
    "    inputs_file = open(input_file_name, 'r')\n",
    "    Lines = inputs_file.readlines()\n",
    "    inputs_temp = [np.fromstring(line.strip(), sep=',') for line in Lines]\n",
    "    for inputs_temp_line in inputs_temp:\n",
    "        inputs.append(inputs_temp_line)\n",
    "\n",
    "    fine_file = open(fine_file_name, 'r')\n",
    "    Lines = fine_file.readlines()\n",
    "    fine_temp = [np.fromstring(line.strip(), sep=',') for line in Lines]\n",
    "    for fine_temp_line in fine_temp:\n",
    "        fine.append(fine_temp_line)\n",
    "\n",
    "    burning_file = open(burning_file_name, 'r')\n",
    "    Lines = burning_file.readlines()\n",
    "    burning_temp = [np.fromstring(line.strip(), sep=',') for line in Lines]\n",
    "    for burning_temp_line in burning_temp:\n",
    "        burning.append(burning_temp_line)\n",
    "\n",
    "    burnedout_file = open(burnedout_file_name, 'r')\n",
    "    Lines = burnedout_file.readlines()\n",
    "    burnedout_temp = [np.fromstring(line.strip(), sep=',') for line in Lines]\n",
    "    for burnedout_temp_line in burnedout_temp:\n",
    "        burnedout.append(burnedout_temp_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b19826",
   "metadata": {},
   "outputs": [],
   "source": [
    "burnedout_percent = burnedout\n",
    "for i in range(10000):\n",
    "    burnedout_percent[i] = burnedout[i]/(fine[i][0]+burning[i][0]+burnedout[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19334eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9229ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1\n",
    "np.random.seed(seed)\n",
    "X_train = to_time_series_dataset(burnedout_percent)\n",
    "sz = X_train.shape[1]\n",
    "\n",
    "km = TimeSeriesKMeans(n_clusters=2, verbose=True, random_state=seed, metric=\"softdtw\")\n",
    "y_pred = km.fit_predict(X_train)\n",
    "plt.figure()\n",
    "for yi in range(4):\n",
    "    plt.subplot(2, 2, yi + 1)\n",
    "    for xx in X_train[y_pred == yi]:\n",
    "        plt.plot(xx.ravel(), \"k-\", alpha=.2)\n",
    "    plt.plot(km.cluster_centers_[yi].ravel(), \"r-\")\n",
    "    plt.xlim(0, sz)\n",
    "    plt.ylim(0, 1)\n",
    "    plt.text(0.55, 0.35,'Cluster %d' % (yi),\n",
    "             transform=plt.gca().transAxes)\n",
    "    if yi == 1:\n",
    "        plt.title(\"soft-DTW $k$-means (mean homogeneity)\")\n",
    "        \n",
    "plt.tight_layout()\n",
    "#plt.savefig('schelling_homogeneity_ts.svg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ada99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1\n",
    "np.random.seed(seed)\n",
    "X_train = to_time_series_dataset(burnedout)\n",
    "sz = X_train.shape[1]\n",
    "\n",
    "km = TimeSeriesKMeans(n_clusters=2, verbose=True, random_state=seed, metric=\"softdtw\")\n",
    "y_pred = km.fit_predict(X_train)\n",
    "plt.figure()\n",
    "for yi in range(4):\n",
    "    plt.subplot(2, 2, yi + 1)\n",
    "    for xx in X_train[y_pred == yi]:\n",
    "        plt.plot(xx.ravel(), \"k-\", alpha=.2)\n",
    "    plt.plot(km.cluster_centers_[yi].ravel(), \"r-\")\n",
    "    plt.xlim(0, sz)\n",
    "    plt.ylim(0, 1)\n",
    "    plt.text(0.55, 0.35,'Cluster %d' % (yi),\n",
    "             transform=plt.gca().transAxes)\n",
    "    if yi == 1:\n",
    "        plt.title(\"soft-DTW $k$-means (mean homogeneity)\")\n",
    "        \n",
    "plt.tight_layout()\n",
    "#plt.savefig('schelling_homogeneity_ts.svg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eff333c",
   "metadata": {},
   "outputs": [],
   "source": [
    "burnedout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63868619",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Mapping the cluster labels back to the inputs - KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe53dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_outputs['softDTW_labels'] = y_pred\n",
    "train_outputs.reset_index(drop=True)\n",
    "backup=train_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ce6ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_outputs[\"0\"].values.reshape(-1, 1), train_outputs[\"softDTW_labels\"],test_size=0.2, random_state = 1)\n",
    "knn_clf=KNeighborsClassifier()\n",
    "knn_clf.fit(X_train,y_train)\n",
    "ypred=knn_clf.predict(X_test) #These are the predicted output values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358dfe6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = confusion_matrix(y_test, ypred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(result)\n",
    "result1 = classification_report(y_test, ypred)\n",
    "print(\"Classification Report:\",)\n",
    "print (result1)\n",
    "result2 = accuracy_score(y_test,ypred)\n",
    "print(\"Accuracy:\",result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93781da",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Mapping the cluster labels back to the inputs - Simple Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2fdae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfafafa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, X_test, Y, y_test = train_test_split(train_outputs[\"0\"].values.reshape(-1, 1), \n",
    "                                                    train_outputs[\"softDTW_labels\"],test_size=0.1, \n",
    "                                                    random_state = 1)\n",
    "\n",
    "#X = np.array(X)\n",
    "\n",
    "dummy_y = np_utils.to_categorical(Y)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(8, input_shape=(X.shape[1],), activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='rmsprop', \n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    " \n",
    "es = keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                   mode='min',\n",
    "                                   patience=10, \n",
    "                                   restore_best_weights=True)\n",
    "\n",
    "history = model.fit(X,\n",
    "                    dummy_y,\n",
    "                    callbacks=[es],\n",
    "                    epochs=500, \n",
    "                    batch_size=10,\n",
    "                    shuffle=True,\n",
    "                    validation_split=0.2,\n",
    "                    verbose=1)\n",
    "\n",
    "history_dict = history.history\n",
    "\n",
    "acc = history_dict['accuracy']\n",
    "val_acc = history_dict['val_accuracy']\n",
    "\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "preds = model.predict(X) \n",
    "print(preds[0]) \n",
    "print(np.sum(preds[0])) \n",
    "\n",
    "matrix = confusion_matrix(dummy_y.argmax(axis=1), preds.argmax(axis=1))\n",
    "matrix\n",
    "print(classification_report(dummy_y.argmax(axis=1), preds.argmax(axis=1)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
